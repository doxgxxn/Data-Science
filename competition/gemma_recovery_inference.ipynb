{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":67121,"databundleVersionId":7806901,"sourceType":"competition"},{"sourceId":7715453,"sourceType":"datasetVersion","datasetId":4505960},{"sourceId":7715470,"sourceType":"datasetVersion","datasetId":4505971},{"sourceId":7747717,"sourceType":"datasetVersion","datasetId":4506214},{"sourceId":8156747,"sourceType":"datasetVersion","datasetId":4812262},{"sourceId":11358,"sourceType":"modelInstanceVersion","modelInstanceId":5383},{"sourceId":11382,"sourceType":"modelInstanceVersion","modelInstanceId":8318}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-18T14:24:00.678760Z","iopub.execute_input":"2024-04-18T14:24:00.679385Z","iopub.status.idle":"2024-04-18T14:24:21.853531Z","shell.execute_reply.started":"2024-04-18T14:24:00.679354Z","shell.execute_reply":"2024-04-18T14:24:21.852742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:21.855246Z","iopub.execute_input":"2024-04-18T14:24:21.856186Z","iopub.status.idle":"2024-04-18T14:24:21.860399Z","shell.execute_reply.started":"2024-04-18T14:24:21.856152Z","shell.execute_reply":"2024-04-18T14:24:21.859527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/llm-prompt-recovery/train.csv\")\ntest= pd.read_csv(\"/kaggle/input/llm-prompt-recovery/test.csv\")\ns_test = pd.read_csv(\"/kaggle/input/gemma-rewrite-nbroad/nbroad-v1.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:21.861498Z","iopub.execute_input":"2024-04-18T14:24:21.861841Z","iopub.status.idle":"2024-04-18T14:24:22.120814Z","shell.execute_reply.started":"2024-04-18T14:24:21.861812Z","shell.execute_reply":"2024-04-18T14:24:22.119759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\nimport gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:22.123734Z","iopub.execute_input":"2024-04-18T14:24:22.124438Z","iopub.status.idle":"2024-04-18T14:24:22.376673Z","shell.execute_reply.started":"2024-04-18T14:24:22.124401Z","shell.execute_reply":"2024-04-18T14:24:22.375734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def generate_prompt(example):\n#     prompt_list = []\n#     for i in range(len(example['original_text'])):\n#         prompt_list.append(r\"\"\"<bos><start_of_turn>user\n#         original text:\n#         {},\n#         rewritten_text:\n#         {},\n        \n#         Try to understand how the original text was transformed into a new version.\n#         Analyzing the changes in style, theme, etc., please come up with a prompt that might have been used to guide the proper transformation from the original to the rewritten text.\n        \n#         <end_of_turn>\n        \n#         <start_of_turn>model\n#         {}<end_of_turn><eos>\"\"\".format(example['original_text'][i], example['rewritten_text'][i], example['rewrite_prompt'][i]))\n#     return prompt_list","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:22.378015Z","iopub.execute_input":"2024-04-18T14:24:22.378376Z","iopub.status.idle":"2024-04-18T14:24:22.385102Z","shell.execute_reply.started":"2024-04-18T14:24:22.378344Z","shell.execute_reply":"2024-04-18T14:24:22.384365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\nclass AIAssistant():\n    def __init__(self, model_name=\"/kaggle/input/doxgxxn-prompt/doxgxxn_gemma\", tokenizer=\"/kaggle/input/gemma/transformers/2b-it/2\", temperature=0.4, top_k=50, top_p=0.95):\n        \"\"\"Initialize the AI assistant.\"\"\"\n\n        # Initialize attributes\n        self.finetune_model = AutoModelForCausalLM.from_pretrained(model_name, device_map={\"\":0})\n        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer, add_special_tokens=True)\n        self.pipe_finetuned = pipeline(\"text-generation\", model=self.finetune_model, tokenizer=self.tokenizer, max_new_tokens=1024)\n        self.temperature = temperature\n        self.top_k = top_k\n        self.top_p = top_p\n        self.tokenizer.padding_side = 'right'\n    def query(self, original_text, rewritten_text):\n        \"\"\"Query the knowledge base of the AI assistant\"\"\"\n        \n        message = [\n                     {\n                        \"role\": \"user\",\n                        \"content\": \"\"\"original text:\n                                      {},\n                                      rewritten_text:\n                                      {},\n\n                                    Try to understand how the original text was transformed into a new version.\n                                    Analyzing the changes in style, theme, etc., please come up with a prompt that might have been used to guide the proper transformation from the original to the rewritten text.\"\"\".format(original_text, rewritten_text)\n                    }\n                  ]\n        prompt = self.pipe_finetuned.tokenizer.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n        outputs = self.pipe_finetuned(\n                                        prompt,\n                                        do_sample=True,\n                                        temperature=self.temperature,\n                                        top_k=self.top_k,\n                                        top_p=self.top_p,\n                                        add_special_tokens=True\n            \n                                        )\n        return outputs[0]['generated_text'][len(prompt):]\n    \n    def set_temperature(self, temperature):\n        self.temperature = temperature\n        \n    def set_top_k(self, top_k):\n        self.top_k = top_k\n        \n    def set_top_p(self, top_p):\n        self.top_p = top_p","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:22.386487Z","iopub.execute_input":"2024-04-18T14:24:22.386800Z","iopub.status.idle":"2024-04-18T14:24:22.397793Z","shell.execute_reply.started":"2024-04-18T14:24:22.386774Z","shell.execute_reply":"2024-04-18T14:24:22.396869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_assistant = AIAssistant()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:22.398822Z","iopub.execute_input":"2024-04-18T14:24:22.399142Z","iopub.status.idle":"2024-04-18T14:24:57.659598Z","shell.execute_reply.started":"2024-04-18T14:24:22.399110Z","shell.execute_reply":"2024-04-18T14:24:57.658587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub= pd.read_csv(\"/kaggle/input/llm-prompt-recovery/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:57.660903Z","iopub.execute_input":"2024-04-18T14:24:57.661199Z","iopub.status.idle":"2024-04-18T14:24:57.669544Z","shell.execute_reply.started":"2024-04-18T14:24:57.661173Z","shell.execute_reply":"2024-04-18T14:24:57.668701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:57.670840Z","iopub.execute_input":"2024-04-18T14:24:57.671157Z","iopub.status.idle":"2024-04-18T14:24:57.685842Z","shell.execute_reply.started":"2024-04-18T14:24:57.671119Z","shell.execute_reply":"2024-04-18T14:24:57.684948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_test.iloc[3]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:24:57.688914Z","iopub.execute_input":"2024-04-18T14:24:57.689249Z","iopub.status.idle":"2024-04-18T14:24:57.695899Z","shell.execute_reply.started":"2024-04-18T14:24:57.689224Z","shell.execute_reply":"2024-04-18T14:24:57.694871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_test['original_text'][5]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:28:51.152828Z","iopub.execute_input":"2024-04-18T14:28:51.153219Z","iopub.status.idle":"2024-04-18T14:28:51.159815Z","shell.execute_reply.started":"2024-04-18T14:28:51.153190Z","shell.execute_reply":"2024-04-18T14:28:51.158728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_test['rewritten_text'][5]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:28:51.432052Z","iopub.execute_input":"2024-04-18T14:28:51.432404Z","iopub.status.idle":"2024-04-18T14:28:51.438508Z","shell.execute_reply.started":"2024-04-18T14:28:51.432378Z","shell.execute_reply":"2024-04-18T14:28:51.437417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s_test['rewrite_prompt'][5]","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:28:51.681121Z","iopub.execute_input":"2024-04-18T14:28:51.681868Z","iopub.status.idle":"2024-04-18T14:28:51.687407Z","shell.execute_reply.started":"2024-04-18T14:28:51.681841Z","shell.execute_reply":"2024-04-18T14:28:51.686385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(ai_assistant.query(s_test['original_text'][5],s_test['rewritten_text'][5]).strip())","metadata":{"execution":{"iopub.status.busy":"2024-04-18T14:28:35.889421Z","iopub.execute_input":"2024-04-18T14:28:35.890064Z","iopub.status.idle":"2024-04-18T14:28:39.928294Z","shell.execute_reply.started":"2024-04-18T14:28:35.890033Z","shell.execute_reply":"2024-04-18T14:28:39.927389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ai_assistant.query(s_test['original_text'][2],s_test['rewritten_text'][2]).strip()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:48:26.127022Z","iopub.execute_input":"2024-04-16T20:48:26.128154Z","iopub.status.idle":"2024-04-16T20:48:29.227399Z","shell.execute_reply.started":"2024-04-16T20:48:26.128119Z","shell.execute_reply":"2024-04-16T20:48:29.226520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'Write like a 1950s housewife: Write with the optimism and domesticity of a 1950s housewife, emphasizing homemaking, family, and domestic bliss.'","metadata":{}},{"cell_type":"code","source":"ai_assistant.query(s_test['original_text'][5],s_test['rewritten_text'][5]).strip()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T18:31:18.487823Z","iopub.execute_input":"2024-04-16T18:31:18.488578Z","iopub.status.idle":"2024-04-16T18:31:22.011555Z","shell.execute_reply.started":"2024-04-16T18:31:18.488542Z","shell.execute_reply":"2024-04-16T18:31:22.010621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from accelerate import Accelerator\n# accelerator = Accelerator()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T18:31:31.352832Z","iopub.execute_input":"2024-04-16T18:31:31.353464Z","iopub.status.idle":"2024-04-16T18:31:31.359282Z","shell.execute_reply.started":"2024-04-16T18:31:31.353430Z","shell.execute_reply":"2024-04-16T18:31:31.358200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = accelerator.device\ntest['id'] = sub['id'].copy()\n\npbar = tqdm(total=test.shape[0])\n\nDEFAULT_TEXT = \"Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\n\nit = iter(test.iterrows())\nidx, row = next(it, (None, None))\n\nres = []\n\nwhile idx is not None:\n    try:\n        decoded_output = ai_assistant.query(row['original_text'], row['rewritten_text']).strip()\n        res.append([row[\"id\"], decoded_output])\n        print(decoded_output)\n        \n    except Exception as e:\n        print(f\"ERROR: {e}\")\n        res.append([row[\"id\"], DEFAULT_TEXT])\n        \n    finally:\n        idx, row = next(it, (None, None))\n        pbar.update(1)\n\npbar.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-16T18:31:31.737175Z","iopub.execute_input":"2024-04-16T18:31:31.737495Z","iopub.status.idle":"2024-04-16T18:32:24.367455Z","shell.execute_reply.started":"2024-04-16T18:31:31.737470Z","shell.execute_reply":"2024-04-16T18:32:24.366525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(res, columns=['id', 'rewrite_prompt'])\nsub.to_csv(\"submission.csv\", index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2024-04-16T18:32:24.369392Z","iopub.execute_input":"2024-04-16T18:32:24.370023Z","iopub.status.idle":"2024-04-16T18:32:24.382381Z","shell.execute_reply.started":"2024-04-16T18:32:24.369983Z","shell.execute_reply":"2024-04-16T18:32:24.381477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}